{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a0f61e9",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\" markdown=\"1\">Machine Learning Algorithms for Digital Wage Payment Prediction</h1> \n",
    "<h2 style=\"text-align: center;\" markdown=\"2\">An AIMS Masters project in Collaboration with the Global Centre on Digital Wages for Decent Work (ILO)</h2>\n",
    "\n",
    "\n",
    "> *The widespread adoption of digital payments has become increasingly important. In light of this, the aim of this project is to investigate the probability of an individual receiving digital wages in Africa. To achieve this, a series of empirical comparative assessments of machine learning classification algorithms will be conducted. The objective is to determine the effectiveness of these algorithms in predicting digital wage payments. Therefore, this notebook forms part of a larger project that seeks to explore the potential of machine learning in addressing issues related to financial inclusion in Africa.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd6cb2c",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\" markdown=\"3\"> Preliminary Data Exploration and Preparation</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100a41ce",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "[Load the Original Data File](#load-data)   \n",
    "[Save CSV Files](#save-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4e53d7",
   "metadata": {},
   "source": [
    "## Load the Original Data File <a class=\"anchor\" id=\"load-data\"></a>\n",
    "\n",
    "First, we load a few essential modules used in notebook. We have developed several utility functions in the `load_data.py` file located in the `src/data` directory that will be used throughout this project for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b3b8629",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add local functions to the path\n",
    "sys.path.append(os.path.join(os.pardir, 'src'))\n",
    "from data import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21601c9",
   "metadata": {},
   "source": [
    "We first create a function to drop columns with missing values accounting for more than 25% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b69b6ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols_by_na(df, threshold=0.75):\n",
    "    \"\"\"\n",
    "    Drop columns with less than `threshold` non-NA values of total values\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The dataframe to process\n",
    "        \n",
    "    threshold : float, default 0.75\n",
    "        The minimum proportion of non-NA values to keep the column\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        The processed dataframe with dropped columns\n",
    "    \"\"\"\n",
    "    num_rows = df.shape[0]\n",
    "    non_na_counts = df.notna().sum()\n",
    "    keep_cols = non_na_counts[non_na_counts >= num_rows * threshold].index\n",
    "    return df[keep_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f582e9f",
   "metadata": {},
   "source": [
    "We create another function to load the data we require. Several data cleaning procedures have also been implemented within this function to ensure that the final output is partially clean and ready for the next step of preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06ecedc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_african_data(filepath):\n",
    "    \"\"\"\n",
    "    Load the original data from the Global Findex Database as a CSV file \n",
    "    and subset data from the African continent in a correct format \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath : filepath to original csv file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        The processed dataframe \n",
    "    \"\"\"\n",
    "    #load data\n",
    "    filepath = load_data.ORG\n",
    "    global_data_2021 = pd.read_csv(filepath, encoding='latin-1')\n",
    "     \n",
    "        \n",
    "    #subset rows for African countries\n",
    "    africa_and_middle_east_data_2021 = global_data_2021[global_data_2021['regionwb'].isin(\n",
    "        ['Middle East & North Africa (excluding high income)', 'Sub-Saharan Africa (excluding high income)'])]\n",
    "    africa_data_2021 = africa_and_middle_east_data_2021[~africa_and_middle_east_data_2021['economy'].isin(\n",
    "        ['Iran, Islamic Rep.', 'Jordan', 'Iraq', 'Lebanon', 'West Bank and Gaza' ])]\n",
    "    \n",
    "    \n",
    "    #recaliberate the weights to consider population size differences between the countries\n",
    "    #get the sum of unscaled weights for each country\n",
    "    sum_weights_by_country = africa_data_2021.groupby('economy')['wgt'].sum()\n",
    "    # compute the population-scaled weight for each observation\n",
    "    africa_data_2021['pop_scaled_wgt'] = africa_data_2021.apply(lambda row: (row['wgt'] * row['pop_adult']) / \n",
    "                                                               sum_weights_by_country[row['economy']], axis=1)\n",
    "    \n",
    "    \n",
    "    #reorder columns\n",
    "    columns = africa_data_2021.columns.to_list()\n",
    "    new_column_order = columns[0:6] + [columns[len(columns)-1]] + columns[6:len(columns)-1]\n",
    "    africa_data_2021 = africa_data_2021.reindex(new_column_order, axis='columns')\n",
    "    \n",
    "    \n",
    "    #encode the regions\n",
    "    #define function to encode the regions\n",
    "    def encode_regions(data):\n",
    "        data.loc[(data['regionwb'] == 'Middle East & North Africa (excluding high income)'), 'regionwb'] = 1\n",
    "        data.loc[(data['regionwb'] == 'Sub-Saharan Africa (excluding high income)'), 'regionwb'] = 2\n",
    "        return data\n",
    "    # call the function and assign the returned value back\n",
    "    africa_data_2021 = encode_regions(africa_data_2021)\n",
    "    \n",
    "    \n",
    "    #Select only individuals who receive wages\n",
    "    africa_data_2021 = africa_data_2021[(africa_data_2021['fin32']==1)]\n",
    "    africa_data_2021.drop(['fin32'], axis=1, inplace = True)\n",
    "    \n",
    "    #drop columns with less than 75% non-NA values of total values\n",
    "    africa_data_2021 = drop_cols_by_na(africa_data_2021, threshold=0.75)\n",
    "    #drop irrelevant columns to the analysis\n",
    "    africa_data_2021.drop(['economycode', 'wpid_random', 'wgt', 'pop_adult', 'fin45_1', \n",
    "                           'anydigpayment', 'fin20', 'receive_agriculture', 'fin45'], axis=1, inplace = True)\n",
    "    \n",
    "    \n",
    "    #drop columns with duplicate information (same info in other columns)\n",
    "    '''\n",
    "    --------------------------------------------------------------\n",
    "    | Remove                          | Retain                    |\n",
    "    |-------------------------------------------------------------|\n",
    "    | account_fin, account_mob, fin2  | account                   |\n",
    "    | saved                           | fin16, fin17a, fin17b     |\n",
    "    | borrowed                        | fin20, fin22a, fin22b     |\n",
    "    | fin24a, fin24b                  | fin24                     |\n",
    "    | fin26, fin28                    | remittances               |\n",
    "    | fin34a, fin34b, fin34d, fin34e  | receive_wages             |\n",
    "    | fin37                           | receive_transfers         |\n",
    "    | fin38                           | receive_pension           |\n",
    "    | fin42                           | receive_agriculture       |\n",
    "    | fin44a, fin44b, fin44c, fin44d  | fin45                     |\n",
    "    | fin30                           | pay_utilities             |\n",
    "    |_____________________________________________________________|\n",
    "    \n",
    "    '''\n",
    "    # 'fin34d', 'fin34e' already dropped by drop_cols_by_na()\n",
    "    africa_data_2021.drop(['account_fin', 'account_mob', 'fin2', 'saved', 'borrowed', 'fin24a', 'fin24b', \n",
    "                           'fin26', 'fin28', 'fin34a', 'fin34b', 'fin37', 'fin38', 'fin42', \n",
    "                           'fin44a', 'fin44b', 'fin44c', 'fin44d', 'fin30'], axis=1, inplace = True)\n",
    "    \n",
    "    \n",
    "    #convert dk and rf to nos\n",
    "    def replace_values(df):\n",
    "        replacements = {\n",
    "            'educ': {4: 1, 5: 1},\n",
    "#             'fin2': {3: 2, 4: 2},\n",
    "            'fin14_1': {3: 2, 4: 2},\n",
    "            'fin14a': {3: 2, 4: 2},\n",
    "            'fin14a1': {3: 2, 4: 2},\n",
    "            'fin14b': {3: 2, 4: 2},\n",
    "            'fin16': {3: 2, 4: 2},\n",
    "            'fin17a': {3: 2, 4: 2},\n",
    "            'fin17b': {3: 2, 4: 2},\n",
    "#             'fin20': {3: 2, 4: 2},\n",
    "            'fin22a': {3: 2, 4: 2},\n",
    "            'fin22b': {3: 2, 4: 2},\n",
    "            'fin24': {8: 7, 9: 7},\n",
    "#             'fin26': {3: 2, 4: 2},\n",
    "#             'fin28': {3: 2, 4: 2},\n",
    "#             'fin32': {3: 2, 4: 2},\n",
    "            'fin33': {3: 2, 4: 2},\n",
    "            'fin45': {6: 5},\n",
    "#             'fin45_1': {5: 3, 4: 3},\n",
    "            'receive_transfers': {5: 4},\n",
    "            'receive_pension': {5: 4},\n",
    "#             'receive_agriculture': {5: 4},\n",
    "            'pay_utilities': {5: 4},\n",
    "            'remittances': {6: 5},\n",
    "            'mobileowner': {3: 2, 4: 2},\n",
    "            'internetaccess': {3: 2, 4: 2}\n",
    "        }\n",
    "        return df.replace(replacements)\n",
    "    africa_data_2021 = replace_values(africa_data_2021)\n",
    "    \n",
    "    # merge receive transfers and receive pension to one feature receive welfare payments\n",
    "    africa_data_2021[\"receive_welfare_payments\"] = 1\n",
    "    africa_data_2021.loc[(africa_data_2021['receive_transfers'] == 4) | (africa_data_2021['receive_pension'] == 4), \n",
    "                     'receive_welfare_payments'] = 2\n",
    "    africa_data_2021.drop(['receive_transfers', 'receive_pension'], axis=1, inplace = True)\n",
    "    \n",
    "    #merge fin14a, fin14a1 and fin14b into one feature internet_fin_transc (used internet for financial transactions)\n",
    "    africa_data_2021[\"internet_fin_transc\"] = 2\n",
    "    africa_data_2021.loc[(africa_data_2021['fin14a'] == 1) | (africa_data_2021['fin14a1'] == 1) | \n",
    "                         (africa_data_2021['fin14b'] == 1), 'internet_fin_transc'] = 1\n",
    "    africa_data_2021.drop(['fin14a', 'fin14a1', 'fin14b'], axis=1, inplace = True)\n",
    "    \n",
    "    return africa_data_2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47089f0e",
   "metadata": {},
   "source": [
    "We apply the above two functions to the downloaded file from the Global Findex database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0720c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = load_data.ORG\n",
    "africa_data_2021 = get_african_data(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a6bd2c",
   "metadata": {},
   "source": [
    "## Save CSV Files <a class=\"anchor\" id=\"load-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6e165",
   "metadata": {},
   "source": [
    "We first of all save a csv file with full feature set to the necessary file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f439191",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = load_data.FULL_MERGED\n",
    "africa_data_2021.to_csv(filepath, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79413c8",
   "metadata": {},
   "source": [
    "We then save another csv file with only demographic-related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74784f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMOGRAPHIC_FEATURES = ['economy', 'regionwb', 'pop_scaled_wgt', 'female', 'age', 'educ', 'inc_q', 'emp_in', \n",
    "                        'urbanicity_f2f', 'account', 'fin33', 'receive_wages', 'mobileowner', \n",
    "                        'internetaccess', 'receive_welfare_payments']\n",
    "africa_data_2021 = africa_data_2021[DEMOGRAPHIC_FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8f2f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = load_data.DEM_MERGED\n",
    "africa_data_2021.to_csv(filepath, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a705fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
